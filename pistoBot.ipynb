{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pistoBot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishwarajanand/pistoBot/blob/master/pistoBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMBML9lTaLva"
      },
      "source": [
        "# **ü§ñ pistoBot**\n",
        "\n",
        "> Create an AI that (try) to chat like you.<br>\n",
        "> by [Simone Guardati](https://www.linkedin.com/in/simone-guardati/)\n",
        "\n",
        "\n",
        "## ü•ú In a nutshell\n",
        "1. Get your whatsapp and telegram data\n",
        "2. Parse it to get a ML-like dataset\n",
        "3. Train a GTP2 model\n",
        "4. Chat with the model\n",
        "\n",
        "**üîó Resources**\n",
        "- Chat parser - [github](https://github.com/GuardatiSimone/messaging-chat-parser)\n",
        "- pistoBot - [github](https://github.com/GuardatiSimone/pistoBot)\n",
        "- pistoBot website - [link](https://guardatisimone.github.io/pistoBot-website/)\n",
        "\n",
        "<br>\n",
        "\n",
        "**‚ö†Ô∏è Warning**\n",
        "- It's always better not to run random scripts on personal information (like personal chat messages).\n",
        "- I guarantee there is no double end, but you can always check (and use) the native code: <br>\n",
        "[messaging-chat-parser](https://github.com/GuardatiSimone/messaging-chat-parser) and [pistobot](https://github.com/GuardatiSimone/pistoBot)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GLofGtbgR5c"
      },
      "source": [
        "------\n",
        "## 0Ô∏è‚É£ Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zasps9vfHk0"
      },
      "source": [
        "!nvidia-smi # p100 suggested"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clix8N59cqqL"
      },
      "source": [
        "import os\n",
        "!git clone --quiet https://github.com/GuardatiSimone/messaging-chat-parser.git\n",
        "!pip install -q -r messaging-chat-parser/requirements.txt\n",
        "!git clone --quiet https://github.com/GuardatiSimone/pistoBot.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qEkk-YZbDN_"
      },
      "source": [
        "-----\n",
        "## 1Ô∏è‚É£ Get the data\n",
        "> Get your chat from whatsapp and telegram and upload them under `./messaging-chat-parser/data/chat_raw/` notebook folder\n",
        "\n",
        "\n",
        "- **WhatsApp**\n",
        "    - _.txt_ files exported from one or more chat - [how](https://faq.whatsapp.com/en/android/23756533/) (under \"Export chat history\" section)\n",
        "        - don't export images\n",
        "        - don't export group chats\n",
        "    - place all txt files in `./messaging-chat-parser/data/chat_raw/whatsapp/*.txt`\n",
        "- **Telegram** \n",
        "    - _.json_ with the telegram dump - [how](https://telegram.org/blog/export-and-more)\n",
        "        - don't export images\n",
        "        - choose \"machine-readable JSON\"\n",
        "    - copy and rename the json file in `./messaging-chat-parser/data/chat_raw/telegram/telegram_dump.json`\n",
        "\n",
        "\n",
        "------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq_6S7lCemLW"
      },
      "source": [
        "## 2Ô∏è‚É£ Parse the data\n",
        "\n",
        "**Whatsapp**\n",
        "- Set the following variable `whatsapp_user_name`\n",
        "    - Get it from one of the WhatsApp chat exported text. \n",
        "    <br> e.g. from one line: <br> \n",
        "     _12/12/19, 08:40 - `whatsapp_user_name`: bla bla bla_ \n",
        "- Datetime:\n",
        "    - WhatsApp and Telegram have two different ways to manage the datetime.\n",
        "    - Here are listed the two format, with Italian default values, if your data have different formats, change accordingly the next line values\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHSOoxejg8s4"
      },
      "source": [
        "whatsapp_user_name = None\n",
        "whatsapp_datetime_format = \"%d/%m/%y, %H:%M\"\n",
        "telegram_datetime_format = \"%Y-%m-%dT%H:%M:%S\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3_N2WUso_XI"
      },
      "source": [
        "# Whatsapp\n",
        "print(\"> [WHATSAPP] start parsing...\")\n",
        "assert whatsapp_user_name is not None, \"[!] Whatsapp user name not setted\"\n",
        "!cd messaging-chat-parser && python ./src/whatsapp_parser.py --session_token \"<|endoftext|>\" --user_name $whatsapp_user_name --time_format \"$whatsapp_datetime_format\"\n",
        "print(\"> [WHATSAPP] parsing completed!\\n\\n\")\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# Telegram\n",
        "print(\"> [TELEGRAM] start parsing...\")\n",
        "assert os.path.exists(\"./messaging-chat-parser/data/chat_raw/telegram/telegram_dump.json\") is not None, \"[!] `telegram_dump.json` not loaded\"\n",
        "!cd messaging-chat-parser && python ./src/telegram_parser.py --session_token \"<|endoftext|>\" --time_format \"$telegram_datetime_format\"\n",
        "print(\"> [TELEGRAM] parsing completed!\\n\\n\")\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# Join Telegram and Whatsapp data\n",
        "!cd messaging-chat-parser/ && python ./src/joiner.py\n",
        "training_data_lines = sum(1 for line in open('./messaging-chat-parser/data/chat_parsed/all-messages.txt'))\n",
        "print(f\"> [PARSER] Training file lines: {training_data_lines}\")\n",
        "print(\"----------------------------------\")\n",
        "\n",
        "# Check data size\n",
        "if training_data_lines < 100000:\n",
        "    print(f\"[WARNING] attention insufficient training data ({training_data_lines} < 100K), it is recommended to export more chats\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDiyALCfsOwq"
      },
      "source": [
        "------\n",
        "## 3Ô∏è‚É£ Train a GTP2 model\n",
        "\n",
        "- ‚è≥ The following cell could take **up to 10 hours**\n",
        "    - An estimation of the total time will be prompted\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwHVtFvPfBXg"
      },
      "source": [
        "!cp ./messaging-chat-parser/data/chat_parsed/all-messages.txt ./pistoBot/data/inputs/chat_parsed/all-messages-endoftext.txt\n",
        "!cd pistoBot/colab/ && bash run_training.sh gpt2-scratch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a94toYckhHIR"
      },
      "source": [
        "---\n",
        "## 4Ô∏è‚É£ Chat with the model\n",
        "\n",
        "Load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-ivHvsOhaNc"
      },
      "source": [
        "from aitextgen import aitextgen\n",
        "from pprint import pprint\n",
        "\n",
        "files = os.listdir(\"./pistoBot/data/models_trained/\")\n",
        "files.remove('.gitkeep')\n",
        "folder_name = files[0]\n",
        "\n",
        "model_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models_trained\", folder_name, \"pytorch_model.bin\")\n",
        "config_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models_trained\", folder_name,\"config.json\")\n",
        "vocab_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models_trained\", folder_name,\"aitextgen-vocab.json\")\n",
        "merges_path = os.path.join(\".\", \"pistoBot\", \"data\", \"models_trained\", folder_name,\"aitextgen-merges.txt\")\n",
        "\n",
        "ai = aitextgen(model=model_path, \n",
        "               config=config_path,\n",
        "               vocab_file=vocab_path,\n",
        "               merges_file=merges_path,\n",
        "               to_gpu=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbLNJlQokvYf"
      },
      "source": [
        "### üí¨ Interactive mode\n",
        "> Chat with the model one message at a time\n",
        "\n",
        "- Run the following cell and use the prompt (‚úç) to write your messages\n",
        "- The chats messages will show two tags:\n",
        "    - **[others]** tags: messages wrote by the user\n",
        "    - **[me]** tags: messages generated by the model\n",
        "\n",
        "<br>\n",
        "\n",
        "- Error _Max temperature reached_:\n",
        "    - **Solution**: re-run the cell\n",
        "    - Motivation: under the hood the program increase the _temperature_ value to get a new message that start with \"[me]\" tag. This is done until a max value is reached.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBwemFaak1kV"
      },
      "source": [
        "chat = []\n",
        "start_temperature = 0.7\n",
        "max_temperature = 3.0\n",
        "\n",
        "for _ in range(5):\n",
        "    new_line = \"[others] \" + input(\"‚úç\") + '\\n'\n",
        "    chat.append(new_line)\n",
        "    \n",
        "    me_token = False\n",
        "    temperature = start_temperature\n",
        "    input_network = ' '.join(chat)\n",
        "    \n",
        "    while not me_token:\n",
        "        text = ai.generate(prompt=input_network, \n",
        "                           return_as_list=True, \n",
        "                           temperature=temperature)\n",
        "        text = text[0] # batch of 1\n",
        "\n",
        "        text = text.split('\\n')\n",
        "        chat_pos = len(chat)\n",
        "        network_reply = text[chat_pos]\n",
        "\n",
        "        if network_reply.startswith('[me]'):\n",
        "            me_token = True\n",
        "            network_reply = text[chat_pos] + '\\n'\n",
        "            chat.append(network_reply)\n",
        "        else:\n",
        "            if temperature >= max_temperature:\n",
        "                raise RuntimeError(\"Max temperature reached\")\n",
        "            temperature += 0.1\n",
        "    # print(f'temperature exit: {temperature}')\n",
        "    print('Chat:')\n",
        "    pprint(chat)\n",
        "    print('---------------------')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}